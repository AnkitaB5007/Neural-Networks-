{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"wiF13r5RZogG"},"source":["Microsoft Teams Name - Tanvi Ajay Gunjal, Ankita Behura\n","Name - Tanvi Ajay Gunjal\n","Matriculation Number - 7002984\n","Name - Ankita Behura\n","Matriculation Number - 7002639\n","Tutor  - Redion Xhepa *italicized text*\n"]},{"cell_type":"code","metadata":{"id":"d_oQejU77kwh"},"source":["import numpy as np\n","import pandas as pd\n","import torch\n","from torchvision.datasets import CIFAR10\n","from sklearn.preprocessing import StandardScaler\n","from numpy.linalg import eig\n","\n","# Download the dataset and save it to a local folder. You should use the train set.\n","cifar_10 = CIFAR10(root=\"C:/Users/acer/Documents/Neural Network/cifar-10-python.tar/cifar-10-python/cifar-10-batches-py\", download=True, train=True)\n","\n","# Create two variables that contain the labels and the image tensors.\n","X, Y = cifar_10.data, cifar_10.targets\n","print(X.shape)\n","\n","# Flatten the train data such that each image is represented as a 1D vector.\n","# The size of the vector is 32 x 32 x 3 = 3072\n","X_flat = X.reshape(-1, 3072)\n","print(X_flat.shape)\n","\n","# Center the data by subtracting the mean from each row\n","M = np.mean(X_flat)\n","X_flat = X_flat - M\n","\n","# We suggest to use a pandas data frame to store the data, but you can deviate \n","# from this if some other package suits you better.\n","col_names = [\"feature_\" + str(i) for i in range(X_flat.shape[1])]\n","df_cifar_10 = pd.DataFrame(X_flat, columns=col_names)\n","df_cifar_10['target'] = Y\n","print(df_cifar_10.head())\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u-20qVzBQ3co"},"source":["x = torch.from_numpy(X_flat[:5000])\n","y = torch.from_numpy(np.array(Y[:5000]))\n","\n","cov_matrix = torch.matmul(x, x.T)\n","cov_matrix.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uWijIFq8dLDQ"},"source":["\n","value, vector = torch.eig(cov_matrix, eigenvectors=True)\n","\n","\n","indices=torch.argsort(value, descending=True)\n","eig_value= value[indices]\n","eig_vec= vector[:,indices]\n","\n","n_components = 2\n","eig = eig_vec[:,:n_components]\n","x_red = torch.matmul(eig.T, cov_matrix).T\n","x_red.shape\n","\n","plt.scatter(x,y, c=Y.numpy())\n","plt.show()\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VFx14W4S1Z-u"},"source":[],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cVfTv0yPTuTB"},"source":["#m = torch.from_numpy(X_flat)\n","data =np.dot(X_flat, Eig_vector)\n","print(data)\n","data.shape\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LTgjdnzjTztW"},"source":["from sklearn.decomposition import PCA\n","from matplotlib import pyplot as plt\n","\n","pca = PCA(n_components=2)\n","pca_new = pca.fit_transform(data)\n","print(pca.explained_variance_ratio_)\n","pca = PCA().fit(t1)\n","plt.xlabel(\"PCA1\")\n","plt.ylabel(\"PCA2\")\n","plt.plot(np.cumsum(pca.explained_variance_ratio_))\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hWGumLAhmNlC"},"source":["fig = plt.figure()\n","ax = plt.axes(projection=\"3d\")\n","\n","x, y, z = data[:,0], data[:,1], data[:,2]\n","\n","z_points = 15 * np.random.random(100)\n","x_points = np.cos(z_points) + 0.1 * np.random.randn(100)\n","y_points = np.sin(z_points) + 0.1 * np.random.randn(100)\n","ax.scatter3D(x_points, y_points, z_points, c=z_points, cmap='hsv')\n","\n","ax.set_xlabel(\"PC1\")\n","ax.set_ylabel(\"PC2\")\n","ax.set_zlabel(\"PC3\")\n","\n","plt.show()\n"],"execution_count":null,"outputs":[]}]}